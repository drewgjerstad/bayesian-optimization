{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4da9584",
   "metadata": {},
   "source": [
    "# Bayesian Decision Theory\n",
    "**Drew Gjerstad**  \n",
    "\n",
    "_Bayesian Optimization Series_  \n",
    "[github.com/drewgjerstad/bayesian-optimization](https://github.com/drewgjerstad/bayesian-optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd16471b",
   "metadata": {},
   "source": [
    "The optimization process in its most basic form is a series of decisions.\n",
    "Ideally, these decisions are made via a principled approach (i.e.,\n",
    "strategically) which is where **decision theory** comes into play. Specifically,\n",
    "the approach used to make such decisions should take into account any available\n",
    "data when deciding where each observation is made. Unfortunately, it is not\n",
    "clear how to make these decisions primarily due to the likely incomplete and\n",
    "ever-changing information about the objective function. \n",
    "\n",
    "Previously, we discussed how to use Bayesian inference as a framework that\n",
    "systematically and quantitatively reasons about the uncertainty in the objective\n",
    "function. This is one of the main difficulties when making decisions during\n",
    "optimization since our knowledge of the objective function is only updated from\n",
    "the outcomes of our own decisions.\n",
    "\n",
    "In this notebook, we focus on Bayesian decision theory which in effect, \"bridges\n",
    "the gap\" between Bayesian inference and decision making in optimization. This\n",
    "principled approach allows us to make decisions using a probabilistic belief\n",
    "about the objective function to guide optimization policies under uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e760e63",
   "metadata": {},
   "source": [
    "At the heart of the optimization process is the _optimization policy_ which\n",
    "determines where we will make an observation next (for the time being, ignoring\n",
    "the question of termination), acquires the next observation, and updates our\n",
    "knowledge of the objective. Therefore, we aim to obtain the **optimal policy**\n",
    "with optimal referring to maximizing the expected utility and quality of the\n",
    "observed data.\n",
    "\n",
    "While the idea of deriving this optimal policy may seem simple, especially when\n",
    "deriving it in a theoretical manner, the theoretically optimal policy is often\n",
    "impossible to compute and has little practical value. Regardless, the process of\n",
    "deriving this policy will enable us to see how we can obtain effective\n",
    "_approximations_.\n",
    "\n",
    "Coming back to the question of termination, this question itself represents a\n",
    "decision that is crucial in several applications. A **stopping rule** is a\n",
    "procedure that decides whether to terminate or continue optimization based on\n",
    "the observed data. In many cases, this rule is _deterministic_ meaning it is\n",
    "fixed and known before we begin optimizing. One example is a preallocated search\n",
    "budget defined by the maximum number of allowed observations. This type of\n",
    "stopping rule will terminate the optimization once we obtain the maximum number\n",
    "of allowed observations, regardless of our progress.\n",
    "\n",
    "Alternatively, we may want to consider the optimization progress (i.e., our\n",
    "understanding of the objective function and the expected cost of continuing)\n",
    "when deciding whether to terminate or not. This is a more _dynamic_ stopping\n",
    "rule that will require more subtle, adaptive stopping rules. We will discuss\n",
    "this more later and how its formulation inspires better approximations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf848cf4",
   "metadata": {},
   "source": [
    "## Defining Optimization Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c5bfd",
   "metadata": {},
   "source": [
    "To define an optimization policy, we typically use an intermediate function\n",
    "called the **acquisition function** that will score each observation candidate\n",
    "based on its utility to aiding the optimization process. Then, the policy can\n",
    "be defined to observe the point deemed to be most useful (or most \"promising\")\n",
    "by the acquisition function. Such a definition is used by nearly all Bayesian\n",
    "optimization policies, with some literature (as noted by Garnett) using the term\n",
    "\"acquisition function\" interchangeably with \"policy\".\n",
    "\n",
    "When using the Bayesian approach, the acquisition function is almost always\n",
    "defined by obtaining the posterior belief (distribution) of the objective given\n",
    "the data and then defining our preferences for the next observation with respect\n",
    "to this belief. Using the notation from Garnett's book, we will denote\n",
    "$\\alpha(x;\\mathcal{D})$ for a general acquisition function with the data,\n",
    "$\\mathcal{D}$, serving as parameters that shape our preferences.\n",
    "\n",
    "In more mathematical terms, an acquisition function $\\alpha$ defines preferences\n",
    "over candidate observations by \"inducing a total order over the domain\". This\n",
    "means that given existing data $\\mathcal{D}$, observing candidate $x$ is\n",
    "preferred over another candidate $x^\\prime$ if\n",
    "$\\alpha(x;\\mathcal{D}) > \\alpha(x^\\prime;\\mathcal{D})$.  Rationally, the action\n",
    "we will prefer is one that maximizes the acquisition function:\n",
    "\n",
    "\\begin{equation*}\n",
    "    x \\in \\argmax_{x^\\prime\\in\\mathcal{X}} \\alpha(x^\\prime;\\mathcal{D})\n",
    "\\end{equation*}\n",
    "\n",
    "We can use the formulation above as a kind of \"sub-optimization problem\". Once\n",
    "it is solved, the acquisition function will map a set of observed data to a\n",
    "candidate $x \\in \\mathcal{X}$ to observe next, filling the exact role of an\n",
    "optimization policy.\n",
    "\n",
    "If you are thinking that the idea of solving global optimization problems by\n",
    "repeatedly solving global optimization problems is unintuitive, don't worry! In\n",
    "many cases, this paradox is resolved by the fact that common acquisition\n",
    "functions have properties making their optimization much more tractable than the\n",
    "primary optimization problem we are aiming to solve.\n",
    "\n",
    "Commonly used acquisition functions are both inexpensive to evaluate and are\n",
    "analytically differentiable which means we can use pre-defined optimizers while\n",
    "computing the policy formulated above. However, recall that our objective\n",
    "function is assumed to be rather expensive to evaluate and lacks efficient (if\n",
    "any at all) gradients. Using the ideas outlined here, we are able to moderate\n",
    "a difficult problem to several simpler problems, a reasonable first step!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531d5df0",
   "metadata": {},
   "source": [
    "## Formalizing Bayesian Decision Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2a70e",
   "metadata": {},
   "source": [
    "Bayesian decision theory is a framework that we can use to make decisions under\n",
    "uncertainty while still being flexible enough that it can be applied to nearly\n",
    "any problem. Here, we introduce Bayesian decision theory in the same manner as\n",
    "Garnett: focusing on the key concepts through the lense of optimization rather\n",
    "than unloading the entire theory abstractly. Garnett recommends the following\n",
    "supplementary texts for a more thorough and in-depth review of the theory:\n",
    " * _Optimal Statistical Decisions_ by M. H. DeGroot\n",
    " * _Statistical Decision Theory and Bayesian Analysis_ by J. O. Berger\n",
    "\n",
    "Being sufficiently familiar with this topic can help you understand key concepts\n",
    "in Bayesian optimization that are examined in the literature less thoroughly\n",
    "than they perhaps should be. In particular, this topic, as Garnett puts it,\n",
    "serves as the \"hidden origin\" of several typical acquisition functions.\n",
    "\n",
    "Following from Garnett's text, we start with using the Bayesian decision theory\n",
    "approach for decision making and examine the case of making a single, isolated\n",
    "decision to see how the framework is used to make optimal decisions. Then, we\n",
    "will extend this reasoning to make several, or a sequence of, decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c430b6",
   "metadata": {},
   "source": [
    "### Case 1: Single, Isolated Decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37cf2c",
   "metadata": {},
   "source": [
    "There are two defining characteristics of a decision problem under uncertainty:\n",
    "the action space and the presence of uncertain elements in the environment. We\n",
    "will review these characteristics first.\n",
    "\n",
    "The **action space** $\\mathcal{A}$ is the set of all available decisions. Keep\n",
    "in mind that the task at hand is to select an action from this space. In the\n",
    "context of sequential optimization, we are selecting a point in the domain\n",
    "$\\mathcal{X}$ to observe so we have that $\\mathcal{A}=\\mathcal{X}$.\n",
    "\n",
    "The **presence of uncertain elements** in the environment will inherently\n",
    "influence the results of our actions which complicates our decision. Using\n",
    "Garnett's notation, let $\\psi$ denote a random variable that encompasses any\n",
    "relevant uncertain elements when making and evaluating a decision. While we may\n",
    "not have all the information about the uncertainty, we can use Bayesian\n",
    "inference to reason about $\\psi$ given the observed data using the posterior\n",
    "distribution $p(\\psi\\vert\\mathcal{D})$. We can use this belief to aid our\n",
    "decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b8a21",
   "metadata": {},
   "source": [
    "Suppose that now we need to make a decision (selected from the action space,\n",
    "$\\mathcal{A}$) under the uncertainty in $\\psi$, and informed by observed data\n",
    "$\\mathcal{D}$. We need some way to guide our decision selection process: a\n",
    "_utility function_.\n",
    "\n",
    "A real-valued **utility-function** $u(a, \\psi, \\mathcal{D})$ is used to guide\n",
    "our choice by measuring the quality of choosing action $a$ if the true state of\n",
    "the environment is $\\psi$, with higher utilities being preferred since the\n",
    "higher the utility score, the more favorable the outcome. Notice that the\n",
    "arguments provided to the utility function are all that is required to judge the\n",
    "quality of a decision:\n",
    " * the proposed action $a$\n",
    " * observed data informing our current knowledge $\\mathcal{D}$\n",
    " * uncertain elements missing from our knowledge $\\psi$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce7ed05",
   "metadata": {},
   "source": [
    "Since we have incomplete information about $\\psi$, we are unable to know the\n",
    "exact utility of selecting any given action. However, we can compute the\n",
    "_expected_ utility of selecting an action $a$ based on our posterior belief:\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathbb{E}\\left[u(a,\\psi,\\mathcal{D})\\vert a,\\mathcal{D}\\right] =\n",
    "    \\int u(a,\\psi,\\mathcal{D})p(\\psi\\vert\\mathcal{D})d\\psi\n",
    "\\end{equation*}\n",
    "\n",
    "The expected utility above maps each action to a real value that induces a total\n",
    "order and provides a simple method to make our decision. We then select an\n",
    "action that maximizes the expected utility:\n",
    "\n",
    "\\begin{equation*}\n",
    "    a \\in \\argmax_{a^\\prime\\in\\mathcal{A}}\\mathbb{E}\\left[\n",
    "        u(a^\\prime,\\psi,\\mathcal{D})\\vert a^\\prime,\\mathcal{D}\\right]\n",
    "\\end{equation*}\n",
    "\n",
    "By using this approach, the decision is considered to be optimal as there are no\n",
    "other actions that would result in greater expected utility. Furthermore, this\n",
    "method of selecting actions optimally under uncertainty is the central concept\n",
    "of Bayesian decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f617f5",
   "metadata": {},
   "source": [
    "### Case 2: Sequential Decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f2510",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c3d27",
   "metadata": {},
   "source": [
    "bayes opt. by garnett\n",
    "bayes opt theory and practice by liu"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
